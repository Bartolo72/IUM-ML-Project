{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link do repozytorium: [link](https://gitlab-stud.elka.pw.edu.pl/jmarcows/ium_22z_projekt \"https://gitlab-stud.elka.pw.edu.pl/jmarcows/ium_22z_projekt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Proces budowy modeli**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model bazowy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naszym modelem bazowym jest model `LinearRegression` wbudowany w pakiet sklearn. Zadaniem tego modelu jest obliczenie predykcji ilości odsłuchań na kolejny tydzień bazując na danych z ostatniych 4 tygodni. \\\n",
    "W pliku `microservice/models/base_model/base_model.ipynb` znajduje się skrypt przygotwujący dostępne dane do formatu danych wejściowych oraz kod źródłowy modelu."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Format danych wejściowych modelu bazowego**\n",
    "Próbka danych treningowych znajduje się poniżej. Przykład danych treningowych dla modelu bazowego można zobaczyć w pliku `data/training_data/base_model.json`\n",
    "```py\n",
    "[\n",
    "    ...,\n",
    "    {\n",
    "        \"track_id\": \"5LNiqEqpDc8TuqPy79kDBu\",\n",
    "        \"play_count\": 2,\n",
    "        \"play_count_week_1\": 1,\n",
    "        \"play_count_week_2\": 2,\n",
    "        \"play_count_week_3\": 0,\n",
    "        \"play_count_week_4\": 1\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W naszym modelu bazowym wejściem jest czteroelementowy wektor, gdzie każda wartość to ilość odsłuchań danego utworu w kolejnym tygodniu. \\\n",
    "Zważywszy na prostote modelu zdecydowaliśmy się na trenowanie modelu przed każdym generowaniem nowej playlisty. Dane wejściowe zawierają w sobie informacje o ilośći odsłuchań dla każdej piosenki sprzed ostatnich 4 tygodni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model docelowy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_inputs: int,\n",
    "                 num_hidden1: int,\n",
    "                 num_hidden2: int,\n",
    "                 num_outputs: int) -> None:\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(num_inputs, num_hidden1)\n",
    "        self.linear2 = nn.Linear(num_hidden1, num_hidden2)\n",
    "        self.linear3 = nn.Linear(num_hidden2, num_outputs)\n",
    "        self.act_fn = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model docelowy to sieć neuronowa zaimplementowana za pomocą bilbioteki `PyTorch`. W modelu znajdują się dwie warstwy ukryte o określonej ilości neuronów.\n",
    "Zadaniem modelu jest obliczenie predykcji ilości odsłuchań na kolejny tydzień bazując na danych z ostatnich 4 tygodni oraz dodatkowych cechach piosenek (dzięki temu docelowo będzie można wygenerować top listę składającą się z 50 utworów o największej liczbie odsłuchań - należy jednak pamietać, że obejmuje ona okres 4 tygodni).\n",
    "W pliku `microservice/models/adv_model/adv_model.py` znajduje się pełna implementacja modelu oraz jego treningu razem z przygotowaniem danych (uwaga: pliki były przenoszone po ich wykorzystaniu, a zatem poprawność ścieżek nie jest gwarantowana)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykres przedstawiający funkcję straty w trakcie treningu modelu:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![adv_model_losses.png](adv_model_losses.png \"adv_model_losses.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Szczególnie warto zwrócić uwagę na fluktuacje wartości funkcji straty począwszy od około 1800 epoki - wynikają one z faktu, że na modelu została \"wymuszona\" zdolność generalizacji za pomocą opcji \"weight decay\" (współczynnika regularyzacji L2) użytego optymalizatora Adam. Dzięki temu model jest mniej podatny na zjawisko przeuczania."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Format danych wejściowych modelu docelowego**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby otrzymać dane wejściowe dla modelu (do uczenia / testowania) należy:\n",
    "1. Pobrać dane: [link](https://wutwaw-my.sharepoint.com/:u:/g/personal/pawel_zawistowski_pw_edu_pl/EWKqnTFghGlHqHiIVjBDDGoBKdQw12isgMhdWI67Z4479w?e=SsiI7g \"https://wutwaw-my.sharepoint.com/:u:/g/personal/pawel_zawistowski_pw_edu_pl/EWKqnTFghGlHqHiIVjBDDGoBKdQw12isgMhdWI67Z4479w?e=SsiI7g\"),\n",
    "2. Rozpakować pobrany plik zip i umieścić w nowo utworzonym folderze folder `data`,\n",
    "3. Poszczególne pliki .jsonl umieścić w odpowiednich podfolderach wewnątrz folderu data, np. `data/data/sessions/sessions.jsonl`,\n",
    "4. Uruchomić skrypt [data_parser.ipynb](https://gitlab-stud.elka.pw.edu.pl/jmarcows/ium_22z_projekt/-/blob/main/data_parser.ipynb \"https://gitlab-stud.elka.pw.edu.pl/jmarcows/ium_22z_projekt/-/blob/main/data_parser.ipynb\"),\n",
    "5. Plik `unique_ids.json` umieścić w folderze `microservice/`.\n",
    "\n",
    "Po wykonaniu tych kroków wszelkie operacje na danych będą wykonywane wewnątrz poszczególnych skryptów."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Próbka danych treningowych znajduje się poniżej. \n",
    "```py\n",
    "[  # cała paczka danych\n",
    "  [  # tydzień 1\n",
    "    {  # utwór 1\n",
    "      \"track_id\",\n",
    "      \"popularity\",\n",
    "      \"duration_ms\",\n",
    "      \"explicit\",\n",
    "      \"danceability\",\n",
    "      \"energy\",\n",
    "      \"key\",\n",
    "      \"loudness\",\n",
    "      \"speechiness\",\n",
    "      \"acousticness\",\n",
    "      \"instrumentalness\",\n",
    "      \"liveness\",\n",
    "      \"valence\",\n",
    "      \"tempo\",\n",
    "      \"release_date_year\",\n",
    "      \"release_date_week\",\n",
    "      \"play_count\",\n",
    "      \"likes\",\n",
    "      \"number_of_skips\"\n",
    "    },\n",
    "    ... # utwór 2, ..., utwór 4071 (liczba utworów, dla których liczba odtworzeń > 0 (na podstawie całego okresu objętego przez sessions.jsonl))\n",
    "  ],\n",
    "  ...  # tydzień 2, tydzień 3, tydzień 4 (dane z miesiąca wstecz)\n",
    "]\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Porównanie wyników**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Mikroserwis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W repozytorium znajduje się folder `microservice`, w którym znajduje się implementacja mikroserwisu umożliwiającego serwowanie predykcji przy pomocy wybranego modelu. \\\n",
    "Przy implementacji została wykorzystana biblioteka `FastAPI` z racji tego, że jest ona szybka w obsłudze oraz pozwala na szybką skalowalność naszej aplikacji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cała aplikacja została skonteneryzowana za pomocą środowiska Docker. Aby uruchomić aplikację lokalnie należy wykonać komendę z wiersza lini poleceń, znajdując się w katalogu roboczym repozytorium.\n",
    "```\n",
    "docker compose up --build\n",
    "``` \n",
    "Aby wyłączyć kontener należy wykonać:\n",
    "```\n",
    "docker compose down\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Opis endpointów**\n",
    "Dzięki integracji `Swagger UI` z `FastAPI` tworzona jest automatyczna dokumentacja wszystkich endpointów wystawionych na komunikację w naszej aplikacji. Aby się do niej dostać, należy po uruchomieniu kontenera wejść na URL: `localhost:8080/docs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zważając na przejrzystość raportu końcowego zdecydowaliśmy się na umieszczenie krótkiego opisu endpointów:\n",
    "- **/base-model/predict** - POST, służący do generowania jednorazowej predykcji wartości odsłuchań piosenki, za pomocą modelu bazowego, na bazie danych wejściowych zawierających dane odsłuchań z ostatnich 4 tygodni zawartych w ciele zapytania HTTP\n",
    "\n",
    "- **/base-model/predictions** - POST, generuje listę predykcji, za pomocą modelu bazowego, przyjmując listę piosenek w formacie danych wejściowych bazowego modelu (opis wyżej) w ciele zapytania HTTP w fformie pliku JSON\n",
    "\n",
    "- **/model/predictions** - POST, generuje listę predykcji, za pomocą modelu docelowego, przyjmując listę piosenek w formacie danych wejsciowych modelu docelowego (opis wyżej) w ciele zapytania HTTP w formie pliku JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplikacja przetrzymuje wytrenowane modele kolejno w folderach:\n",
    "- `microservice/models/adv_model/adv_model.tar` - dla modelu docelowego \n",
    "- `microservice/models/base_model/base_model.joblib` - dla modelu bazowego"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z racji na wielkość wytrenowanego modelu docelowego zdecydowaliśmy się na nieumieszczanie go w zdalnym repozytorium.\\\n",
    "Model można pobrać klikając w link: https://drive.google.com/file/d/1CfHCXFw5sJv3_L_wfz3bOvEwVosvBJ5g/view?usp=sharing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Eksperymenty A/B**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przed przystąpieniem do testów zakładamy, że model bazowy (oznaczony jako `Base model`) będzie gorszy (względem ustalonej podczas Etapu I metryki) od modelu docelowego (oznaczonego jako `Adv. model`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adv. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 60 - 256\n",
      "1: 454 - 243\n",
      "2: 994 - 241\n",
      "3: 3620 - 238\n",
      "4: 3988 - 238\n",
      "5: 1380 - 237\n",
      "6: 2643 - 237\n",
      "7: 4000 - 236\n",
      "8: 1136 - 235\n",
      "9: 2168 - 233\n",
      "10: 1234 - 232\n",
      "11: 1509 - 231\n",
      "12: 1383 - 229\n",
      "13: 2792 - 229\n",
      "14: 1922 - 229\n",
      "15: 3986 - 226\n",
      "16: 1601 - 226\n",
      "17: 462 - 226\n",
      "18: 1639 - 226\n",
      "19: 901 - 226\n",
      "20: 834 - 225\n",
      "21: 3189 - 225\n",
      "22: 1272 - 225\n",
      "23: 3854 - 225\n",
      "24: 4020 - 224\n",
      "25: 870 - 224\n",
      "26: 2241 - 224\n",
      "27: 1534 - 223\n",
      "28: 263 - 223\n",
      "29: 1111 - 223\n",
      "30: 2699 - 222\n",
      "31: 3344 - 222\n",
      "32: 1231 - 221\n",
      "33: 1097 - 221\n",
      "34: 1732 - 221\n",
      "35: 3266 - 220\n",
      "36: 3437 - 220\n",
      "37: 1157 - 219\n",
      "38: 2778 - 219\n",
      "39: 2382 - 218\n",
      "40: 2913 - 218\n",
      "41: 3521 - 218\n",
      "42: 1959 - 218\n",
      "43: 443 - 217\n",
      "44: 2902 - 216\n",
      "45: 3670 - 216\n",
      "46: 1442 - 216\n",
      "47: 1668 - 216\n",
      "48: 4030 - 215\n",
      "49: 1827 - 215\n"
     ]
    }
   ],
   "source": [
    "dirname = os.path.abspath('')\n",
    "input_path = os.path.join(dirname,\n",
    "                          \"microservice/\"\n",
    "                          \"database/\"\n",
    "                          \"adv_model/\"\n",
    "                          \"2023-01-17_00-33-27/\"\n",
    "                          \"input.json\")\n",
    "output_path = os.path.join(dirname,\n",
    "                           \"microservice/\"\n",
    "                           \"database/\"\n",
    "                           \"adv_model/\"\n",
    "                           \"2023-01-17_00-33-27/\"\n",
    "                           \"output.json\")\n",
    "ranking_path = os.path.join(dirname,\n",
    "                            \"microservice/\"\n",
    "                            \"database/\"\n",
    "                            \"adv_model/\"\n",
    "                            \"2023-01-17_00-33-27/\"\n",
    "                            \"ranking.json\")\n",
    "\n",
    "with open(input_path, 'r') as f:\n",
    "    input_data = json.load(f)\n",
    "\n",
    "data_weeks: List[pd.DataFrame] = []\n",
    "for i, week in enumerate(input_data):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    df = pd.DataFrame(week)\n",
    "    data_weeks.append(df)\n",
    "\n",
    "with open(output_path, 'r') as f:\n",
    "    output_data = json.load(f)\n",
    "\n",
    "\n",
    "def generate_ranking(output_data: List[float],\n",
    "                     data_weeks: List[pd.DataFrame]) -> None:\n",
    "    columns_to_drop = [\"track_id\", \"popularity\", \"duration_ms\", \"explicit\",\n",
    "                       \"danceability\", \"energy\", \"key\", \"loudness\",\n",
    "                       \"speechiness\", \"acousticness\", \"instrumentalness\",\n",
    "                       \"liveness\", \"valence\", \"tempo\", \"release_date_year\",\n",
    "                       \"release_date_week\", \"likes\", \"number_of_skips\"]\n",
    "\n",
    "    for i, df in enumerate(data_weeks):\n",
    "        tmp_df = df.copy()\n",
    "        tmp_df.drop(columns=columns_to_drop, inplace=True)\n",
    "        tmp_df = tmp_df.values.tolist()\n",
    "        tmp_df_2 = []\n",
    "        for row in tmp_df:\n",
    "            tmp_df_2.extend(row)\n",
    "        data_weeks[i] = tmp_df_2\n",
    "\n",
    "    for i in range(len(output_data)):\n",
    "        output_data[i] = (output_data[i] + data_weeks[0][i] +\n",
    "                          data_weeks[1][i] + data_weeks[2][i])\n",
    "\n",
    "    ranking = sorted(range(len(output_data)),\n",
    "                     key=lambda i: output_data[i])\n",
    "    ranking.reverse()\n",
    "\n",
    "    for i, idx in enumerate(ranking[:50]):\n",
    "        print(f\"{i}: {idx} - {round(output_data[idx])}\")\n",
    "\n",
    "    with open(ranking_path, 'w+') as f:\n",
    "        f.write(json.dumps(ranking, indent=4))\n",
    "\n",
    "\n",
    "generate_ranking(output_data, data_weeks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2165 - 275\n",
      "1: 1509 - 274\n",
      "2: 870 - 274\n",
      "3: 60 - 274\n",
      "4: 1057 - 273\n",
      "5: 1960 - 267\n",
      "6: 1354 - 267\n",
      "7: 3189 - 266\n",
      "8: 1442 - 266\n",
      "9: 1424 - 266\n",
      "10: 3949 - 265\n",
      "11: 1383 - 262\n",
      "12: 1351 - 262\n",
      "13: 994 - 261\n",
      "14: 2615 - 260\n",
      "15: 1914 - 260\n",
      "16: 1877 - 260\n",
      "17: 3358 - 259\n",
      "18: 454 - 259\n",
      "19: 4020 - 257\n",
      "20: 2241 - 257\n",
      "21: 740 - 257\n",
      "22: 333 - 257\n",
      "23: 1234 - 256\n",
      "24: 1097 - 256\n",
      "25: 1639 - 255\n",
      "26: 1569 - 255\n",
      "27: 2902 - 253\n",
      "28: 1628 - 253\n",
      "29: 4030 - 252\n",
      "30: 3944 - 252\n",
      "31: 3195 - 252\n",
      "32: 3135 - 252\n",
      "33: 2182 - 250\n",
      "34: 1706 - 250\n",
      "35: 1526 - 250\n",
      "36: 3750 - 249\n",
      "37: 2913 - 249\n",
      "38: 1471 - 249\n",
      "39: 901 - 249\n",
      "40: 853 - 248\n",
      "41: 3854 - 247\n",
      "42: 3510 - 247\n",
      "43: 2703 - 247\n",
      "44: 1380 - 247\n",
      "45: 1136 - 247\n",
      "46: 3457 - 246\n",
      "47: 1534 - 246\n",
      "48: 1111 - 246\n",
      "49: 3266 - 245\n"
     ]
    }
   ],
   "source": [
    "dirname = os.path.abspath('')\n",
    "input_path = os.path.join(dirname,\n",
    "                          \"microservice/\"\n",
    "                          \"database/\"\n",
    "                          \"base_model/\"\n",
    "                          \"2023-01-17_02-12-19/\"\n",
    "                          \"input.json\")\n",
    "output_path = os.path.join(dirname,\n",
    "                           \"microservice/\"\n",
    "                           \"database/\"\n",
    "                           \"base_model/\"\n",
    "                           \"2023-01-17_02-12-19/\"\n",
    "                           \"output.json\")\n",
    "ranking_path = os.path.join(dirname,\n",
    "                            \"microservice/\"\n",
    "                            \"database/\"\n",
    "                            \"base_model/\"\n",
    "                            \"2023-01-17_02-12-19/\"\n",
    "                            \"ranking.json\")\n",
    "unique_ids_path = os.path.join(dirname,\n",
    "                               \"microservice/\"\n",
    "                               \"unique_ids.json\")\n",
    "\n",
    "with open(input_path, 'r') as f:\n",
    "    input_data = json.load(f)\n",
    "\n",
    "with open(unique_ids_path, 'r') as f:\n",
    "    unique_ids = json.load(f)\n",
    "\n",
    "for id in unique_ids:\n",
    "    for i, track in enumerate(input_data):\n",
    "        if id == track[\"track_id\"]:\n",
    "            break\n",
    "        if i == len(input_data) - 1:\n",
    "            tmp = {\n",
    "                \"track_id\": id,\n",
    "                \"play_count_week_1\": 0,\n",
    "                \"play_count_week_2\": 0,\n",
    "                \"play_count_week_3\": 0,\n",
    "                \"play_count_week_4\": 0,\n",
    "                \"play_count\": 0\n",
    "                }\n",
    "            input_data.append(tmp)\n",
    "\n",
    "data_weeks = pd.DataFrame(input_data)\n",
    "data_weeks[\"plays\"] = (data_weeks[\"play_count_week_1\"] +\n",
    "                       data_weeks[\"play_count_week_2\"] +\n",
    "                       data_weeks[\"play_count_week_3\"] +\n",
    "                       data_weeks[\"play_count_week_4\"])\n",
    "data_weeks.sort_values(by=[\"track_id\"], inplace=True, ascending=True)\n",
    "data_weeks.drop(columns=[\"track_id\", \"play_count_week_1\", \"play_count_week_2\",\n",
    "                         \"play_count_week_3\", \"play_count_week_4\", \"play_count\"],\n",
    "                inplace=True)\n",
    "\n",
    "with open(output_path, 'r') as f:\n",
    "    output_data = json.load(f)\n",
    "\n",
    "\n",
    "def generate_ranking(output_data: List[float],\n",
    "                     data_weeks: pd.DataFrame) -> None:\n",
    "    data_weeks = data_weeks.values.tolist()\n",
    "    tmp_df = []\n",
    "    for row in data_weeks:\n",
    "        tmp_df.extend(row)\n",
    "    data_weeks = tmp_df\n",
    "\n",
    "    for i in range(len(output_data)):\n",
    "        output_data[i] = (output_data[i] + data_weeks[i])\n",
    "\n",
    "    ranking = sorted(range(len(output_data)),\n",
    "                     key=lambda i: output_data[i])\n",
    "    ranking.reverse()\n",
    "\n",
    "    for i, idx in enumerate(ranking[:50]):\n",
    "        print(f\"{i}: {idx} - {round(output_data[idx])}\")\n",
    "\n",
    "    with open(ranking_path, 'w+') as f:\n",
    "        f.write(json.dumps(ranking, indent=4))\n",
    "\n",
    "\n",
    "generate_ranking(output_data, data_weeks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adv. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4694.139696753117\n"
     ]
    }
   ],
   "source": [
    "actual_ranking = os.path.join(dirname,\n",
    "                              \"microservice/\"\n",
    "                              \"database/\"\n",
    "                              \"actual_ranking.json\")\n",
    "pred_ranking = os.path.join(dirname,\n",
    "                              \"microservice/\"\n",
    "                              \"database/\"\n",
    "                              \"adv_model/\"\n",
    "                              \"2023-01-17_00-33-27/\"\n",
    "                              \"ranking.json\")\n",
    "\n",
    "with open(actual_ranking, 'r') as f:\n",
    "    ranking_1 = json.load(f)\n",
    "\n",
    "with open(pred_ranking, 'r') as f:\n",
    "    ranking_2 = json.load(f)\n",
    "\n",
    "\n",
    "def calculate_criterion(ranking_1: List[int], ranking_2: List[int]) -> float:\n",
    "    criterion = 0\n",
    "    count_penalty = 0\n",
    "    for i in range(50):\n",
    "        index_1 = i + 1\n",
    "        index_2 = ranking_2.index(ranking_1[i]) + 1\n",
    "        if index_2 == index_1:\n",
    "            count_penalty += 1\n",
    "        criterion += ((index_1 - index_2) ** 2) / (i + 1)\n",
    "    if count_penalty < 40:\n",
    "        criterion *= 10\n",
    "    return criterion\n",
    "\n",
    "\n",
    "print(calculate_criterion(ranking_1, ranking_2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74818.14208782068\n"
     ]
    }
   ],
   "source": [
    "actual_ranking = os.path.join(dirname,\n",
    "                              \"microservice/\"\n",
    "                              \"database/\"\n",
    "                              \"actual_ranking.json\")\n",
    "pred_ranking = os.path.join(dirname,\n",
    "                              \"microservice/\"\n",
    "                              \"database/\"\n",
    "                              \"base_model/\"\n",
    "                              \"2023-01-17_02-12-19/\"\n",
    "                              \"ranking.json\")\n",
    "\n",
    "with open(actual_ranking, 'r') as f:\n",
    "    ranking_1 = json.load(f)\n",
    "\n",
    "with open(pred_ranking, 'r') as f:\n",
    "    ranking_2 = json.load(f)\n",
    "\n",
    "\n",
    "def calculate_criterion(ranking_1: List[int], ranking_2: List[int]) -> float:\n",
    "    criterion = 0\n",
    "    count_penalty = 0\n",
    "    for i in range(50):\n",
    "        index_1 = i + 1\n",
    "        index_2 = ranking_2.index(ranking_1[i]) + 1\n",
    "        if index_2 == index_1:\n",
    "            count_penalty += 1\n",
    "        criterion += ((index_1 - index_2) ** 2) / (i + 1)\n",
    "    if count_penalty < 40:\n",
    "        criterion *= 10\n",
    "    return criterion\n",
    "\n",
    "\n",
    "print(calculate_criterion(ranking_1, ranking_2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po porównaniu wyników modeli wyraźnie widać, że model docelowy jest znacznie lepszy od modelu bazowego (wartość naszej metryki jest dla niego ~16 razy mniejsza).\n",
    "Niestety nie udało nam się spełnić kryterium analitycznego z Etapu I, które zakładało, że wartość tej metryki zejdzie ponieżej `0.2`. Założenie to wynikało z niedocenienia złożoności problemu, który przyszło nam rozwiązywać - taką wartość osiągnąć możnaby było tylko dla co najwyżej kilku błędnych pozycji w top liście (i to na zasadzie zamiany miejsc po sąsiedzku, np. faktyczne pozycje 16 i 17 w naszej predykcji byłby pozycjami 17 i 16 - w rzeczywistości wystarczy, że pozycja jednej piosenki jest np. 10 miejsc dalej niż powinna i już wartość metryki znacznie wykracza poza zakładane kryterium).\\\n",
    "Również kryterium biznesowe (40/50 pozycji poprawnych) nie zostało spełnione, co tłumaczy wspomniane powyżej zjawisko (wystarczy, że 1 piosenka z 50 jest odpowiednio nietrafiona)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
